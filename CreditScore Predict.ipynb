{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/credit-score-prediction/CreditScore_test.csv\n/kaggle/input/credit-score-prediction/CreditScore_train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\n\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MSE_Train = []\nRMSE_Train = []\nMAE_Train = []\nMSE_Test = []\nRMSE_Test = []\nMAE_Test = []\nHyper =[]\nrfestimator = []\ntree_depth = []\nMAPE_Train = []\nMAPE_Test = []\n    ","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Execution Flow\n\ndef ModelFlow():\n    \n                  \n    CreditTrain = pd.read_csv(\"/kaggle/input/credit-score-prediction/CreditScore_train.csv\")\n    CreditTest = pd.read_csv(\"/kaggle/input/credit-score-prediction/CreditScore_test.csv\")\n    \n    #Concatenate both train and test data\n    Credit_Train_Test = pd.concat([CreditTrain,CreditTest],axis=0)\n    #print(\"CreditTrain:\",CreditTrain.head())\n    #print(\"CreditTest:\",CreditTest.head())\n    #print(\"Credit_Train_Test:\",Credit_Train_Test.head())\n\n    #Know the data\n    KnowTheData(Credit_Train_Test)\n    \n    print(\"**********************************************\")\n    print(\"Linear Model Type Build Process starts.....\")\n    Credit_Train_Test_Linear = ModelType(Credit_Train_Test,modeltp = \"linear\")\n            \n    #Split the dataset into train and test after datacleaning and selected the important features for the model.\n    Credit_Train = Credit_Train_Test_Linear.head(80000)\n    Credit_Test = Credit_Train_Test_Linear.tail(20000)\n    \n    print(\"Model Selection Starts for Linear.....\")\n    #Model_Selection\n    X_train,X_test,Y_train,Y_test, Credit_Test = ModelSelection(Credit_Train, Credit_Test)\n    print(\"Model Selection Ends for Linear.....\")\n    \n    #Build Linear Model\n    LinearReg(X_train,X_test,Y_train,Y_test,Credit_Test)\n    \n    #Build Ridge Model\n    RidgeReg(X_train,X_test,Y_train,Y_test,Credit_Test)\n    \n    print(\"Linear Model Type Build Process ends.....\")\n    print(\"**********************************************\")\n    \n    print(\"**********************************************\")\n    print(\"Tree Model Type Build Process starts.....\")\n       \n    Credit_Train_Test_Tree = ModelType(Credit_Train_Test,modeltp = \"Tree\")\n    \n    #Split the dataset into train and test after datacleaning and selected the important features for the model.\n    Credit_Train = Credit_Train_Test_Tree.head(80000)\n    Credit_Test = Credit_Train_Test_Tree.tail(20000)\n    \n    print(\"Model Selection Starts for Tree.....\")\n    #Model_Selection\n    X_train,X_test,Y_train,Y_test, Credit_Test = ModelSelection(Credit_Train, Credit_Test)\n    \n    print(\"Model Selection Ends for Tree.....\")\n    \n    #Build DSRegressor Model\n    DSReg(X_train,X_test,Y_train,Y_test,Credit_Test)\n    \n    #Build RandomForest Regressor Model\n    RandomForestReg(X_train,X_test,Y_train,Y_test,Credit_Test)\n    \n    #Build XGBoost Regressor Model\n    XGBoost(X_train,X_test,Y_train,Y_test,Credit_Test)\n    \n    print(\"**********************************************\")\n    print(\"Tree Model Type Build Process ends.....\")\n    ","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Knowing the data\ndef KnowTheData(Credit_Train_Test):\n    display(\"Shape of the dataframe:\")\n    display(Credit_Train_Test.shape)\n    CreditTrain_data = []\n    CreditTrain_data.append(['FeatureName','DataType','No.ofMiss_Values','Percent_of_Miss_Values'])\n    for col in Credit_Train_Test.columns:\n        CreditTrain_data.append([col,Credit_Train_Test[col].dtypes,Credit_Train_Test[col].isnull().sum(),(Credit_Train_Test[col].isnull().sum() / len(Credit_Train_Test) * 100)])\n    \n    #display(CreditTrain_data)\n    \n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ModelType(Credit_Train_Test,modeltp):\n    if modeltp == \"linear\":\n        Credit_Train_Test = DataCleaning(Credit_Train_Test,modeltp)\n        Credit_Train_Test = Feature_Selection(Credit_Train_Test)\n    else:\n        Credit_Train_Test = DataCleaning(Credit_Train_Test,modeltp)\n    \n    return Credit_Train_Test\n        ","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DataCleaning(Credit_Train_Test,modeltp):\n    DuplicatedData(Credit_Train_Test)\n    if modeltp == \"linear\":\n        print(\"DataCleaning Process Starts For Linear.....\")\n        Credit_Train_Test = DataForImputation(Credit_Train_Test,modeltp)\n        Credit_Train_Test = Imputation(Credit_Train_Test,modeltp)\n        print(\"DataCleaning Process Ends For Linear.....\")\n        \n    else:\n        print(\"DataCleaning Process Starts For Tree.....\")\n        Credit_Train_Test = Imputation(Credit_Train_Test,modeltp)\n        print(\"DataCleaning Process Ends For Tree.....\")\n        \n    return Credit_Train_Test","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DuplicatedData(Credit_Train_Test):\n    print(\"Finding Duplicated Data\")\n    print(\"Total number of duplicate records:\", Credit_Train_Test.duplicated().sum())","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DataForImputation(Credit_Train_Test,modeltp):\n    \n    Features_For_Model = []\n    Missing_count = 0.0\n        \n    if modeltp == 'linear':\n        \n        print(\"DataAnalysis For Imputation Starts For Linear...\")\n        print(\"Drop the features whose greater than equal to 50% of Missing Values:\")\n        \n        for col in Credit_Train_Test.columns:\n            \n            Missing_count = (Credit_Train_Test[col].isnull().sum()/ len(Credit_Train_Test)) * 100\n            if Missing_count < 50:\n                Features_For_Model.append(col)\n            else:\n                \n                #display(Credit_Train_Test[col])\n                Credit_Train_Test.drop(Credit_Train_Test[[col]],axis=1,inplace=True)\n    \n    #display(np.array(Features_For_Model).T)\n    print(\"DataAnalysis For Imputation Ends For Linear...\")\n    \n    return Credit_Train_Test\n    \n        ","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Impute Missing Values:\n\ndef Imputation(Credit_Train_Test,modeltp):\n    \n       \n    if modeltp == \"linear\":\n        print(\"Imputation starts for Linear.....\")\n        for col in Credit_Train_Test.columns:\n            Credit_Train_Test[col].fillna(Credit_Train_Test[col].mean(),inplace=True)\n        print(\"Shape of the Dataframe after Imputation for Linear:\")\n        display(Credit_Train_Test.shape)\n        print(\"Imputation ends for Linear.....\")\n        \n    else:\n        print(\"Imputation starts for Tree.....\")\n        display(Credit_Train_Test.shape)\n        Credit_Train_Test.fillna(0,inplace=True)\n        print(\"Imputation ends for Tree.....\")\n    \n    return Credit_Train_Test\n        \n    ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Feature_Selection(Credit_Train_Test):\n    print(\"Identifying the relationship of independent and dependent variables for Linear\")\n    Credit_Train_Test_Corr = Credit_Train_Test.corr(method='pearson')[['y']].T\n    Credit_Train_Test_Corr = Credit_Train_Test_Corr[Credit_Train_Test_Corr > 0.3]\n    #display(CreditTrain_Corr.columns)\n    Important_Features = []\n    for col in Credit_Train_Test_Corr.columns:\n        if Credit_Train_Test_Corr[col].isnull()[0] != True:\n            Important_Features.append(col)\n                    \n    print(\"Important Features from Correlation for Linear\")\n    #display(Important_Features)\n    #display(Credit_Train_Test_Corr)\n    #Multicolinearity(CreditTrain,Important_Features)  \n    return Credit_Train_Test[Important_Features]\n    ","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def Multicolinearity(CreditTrain,Important_Features):\n #   display(\"Multicolinearity...\")\n  #  CreditTrain_Corr = CreditTrain[Important_Features].corr()\n   # CreditTrain_Corr = CreditTrain_Corr[CreditTrain_Corr < 0.75]\n    #HighMultiColinear_Features = []\n    #display(CreditTrain_Corr)\n    #for col1 in CreditTrain_Corr.columns:\n     #   for col2 in CreditTrain_Corr.columns:\n      #      if col1 != col2 and col1 != 'y' and col2!= 'y' and CreditTrain_Corr[col1][col2] >= 0.75:\n       #         if CreditTrain_Corr[col1]['y'] >= CreditTrain_Corr[col2]['y']:\n        #            if col1 not in HighMultiColinear_Features:\n         #               HighMultiColinear_Features.append(col1)\n                    \n    #display(np.array(HighMultiColinear_Features).T)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ModelSelection(CreditTrain,Credit_Test):\n    print(\"Model Selection Starts.....\")\n    X = CreditTrain.drop('y',axis=1)\n    Y = CreditTrain['y']\n    Credit_Test.drop('y',axis=1,inplace=True)\n    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=10)\n    \n    #print(\"X_train shape:\", X_train.shape)\n    #print(\"X_test shape:\", X_test.shape)\n    #print(\"Y_train shape:\", Y_train.shape)\n    #print(\"Y_test shape:\", Y_test.shape)\n    print(\"Model Selection Ends.....\")\n    return X_train,X_test,Y_train,Y_test,Credit_Test\n    ","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LinearReg(X_train,X_test,Y_train,Y_test,Credit_Test):\n    algo = 'linear'\n    model = LinearRegression()\n    model.fit(X_train,Y_train)\n    print(\"LinearRegression:\")\n    Y_train_predict = model.predict(X_train)\n    Y_test_predict = model.predict(X_test)\n    Y_Credit_test_predict = model.predict(Credit_Test)\n    print(\"********Linear Regression Measures****************\")\n    Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n    Linear_accuracy = pd.DataFrame({\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test,\"MAPE-Train\":MAPE_Train,\"MAPE-Test\":MAPE_Test})\n    ModelPerformance(algo,Linear_accuracy)\n    ","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RidgeReg(X_train,X_test,Y_train,Y_test,Credit_Test):\n    global Hyper\n    algo = 'Ridge'\n    \n    print(\"RidgeRegression:\")\n    print(\"********Ridge Regression Measures****************\")\n    \n    for alpha in range(1,10):\n        model = Ridge(alpha,normalize=True)\n        Hyper.append(alpha)\n        model.fit(X_train,Y_train)\n        Y_train_predict = model.predict(X_train)\n        Y_test_predict = model.predict(X_test)\n        Y_Credit_test_predict = model.predict(Credit_Test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n        \n    Ridge_optimize = pd.DataFrame({\"Penalty\":Hyper,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test,\"MAPE-Train\":MAPE_Train,\"MAPE-Test\":MAPE_Test})\n        \n    ModelPerformance(algo, Ridge_optimize)\n    \n    \n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DSReg(X_train,X_test,Y_train,Y_test,Credit_Test):\n    global Hyper\n    algo = 'ds'\n    print(\"Decision Tree:\")\n    print(\"********Decision Tree Regression Measures****************\")\n    for depth in range(1,20):\n        dsmodel = tree.DecisionTreeRegressor(max_depth=depth)\n        Hyper.append(depth)\n        dsmodel.fit(X_train,Y_train)\n        Y_train_predict = dsmodel.predict(X_train)\n        Y_test_predict = dsmodel.predict(X_test)\n        Y_Credit_test_predict = dsmodel.predict(Credit_Test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n    \n    ds_optimize = pd.DataFrame({\"TreeDepth\":Hyper,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test,\"MAPE-Train\":MAPE_Train,\"MAPE-Test\":MAPE_Test})\n    \n    ModelPerformance(algo,ds_optimize)\n    ","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RandomForestReg(X_train,X_test,Y_train,Y_test,Credit_Test):\n    global rfestimator, tree_depth\n    algo = \"RandomForest\"\n    print(\"**************Random Forest Regressor*****************\")\n    \n    for estimator in range(10,21,2):\n        \n        for depth in range(1,10,2):\n            rfestimator.append(estimator)\n            tree_depth.append(depth)\n            random_model = RandomForestRegressor(n_estimators=estimator,max_depth = depth, random_state=0)\n            random_model.fit(X_train,Y_train)\n            Y_train_predict = random_model.predict(X_train)\n            Y_test_predict = random_model.predict(X_test)\n            Y_Credit_test_predict = random_model.predict(Credit_Test)\n            \n            Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n        \n    random_accuracy = pd.DataFrame({\"No of Trees\":rfestimator,\"Tree Depth\": tree_depth,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test,\"MAPE-Train\":MAPE_Train,\"MAPE-Test\":MAPE_Test})\n    \n    ModelPerformance(algo,random_accuracy)\n    rfestimator = []\n    tree_depth = []\n    \n    ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def XGBoost(X_train,X_test,Y_train,Y_test,Credit_Test):\n    print(\"**************XGBOOST**********************\")\n    global rfestimator, tree_depth\n    algo = \"XGBoost\"\n    estimator = 1000\n    depth = 9\n    #for estimator in range(100,1001,100):\n        \n     #   for depth in range(1,10):\n    rfestimator.append(estimator)\n    tree_depth.append(depth)\n        #xgb_model = xgb.XGBRegressor(n_estimators=estimator, learning_rate=0.1, \n         #                        subsample=0.75,colsample_bytree=1,max_depth=depth,\n          #                       random_state=10,gamma=1)\n    xgb_model = xgb.XGBRegressor(objective ='reg:squarederror')\n\n    xgb_model.fit(X_train,Y_train)\n    Y_train_predict = xgb_model.predict(X_train)\n    Y_test_predict = xgb_model.predict(X_test)\n    Y_Credit_test_predict = xgb_model.predict(Credit_Test)\n    Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n   \n    xgb_accuracy = pd.DataFrame({\"No of Trees\":rfestimator,\"Tree Depth\": tree_depth,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test,\"MAPE-Train\":MAPE_Train,\"MAPE-Test\":MAPE_Test})\n        \n    ModelPerformance(algo,xgb_accuracy)\n    rfestimator = []\n    tree_depth = []\n       ","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict):\n    \n    global MSE_Train, RMSE_Train,MAE_Train, MSE_Test, RMSE_Test, MAE_Test, MAPE_Train, MAPE_Test, Hyper\n    \n    MSE = mean_squared_error(Y_train,Y_train_predict)\n    RMSE = np.sqrt(mean_squared_error(Y_train,Y_train_predict))\n    MAE = mean_absolute_error(Y_train,Y_train_predict)\n    MAPE = np.mean(np.abs((Y_train - Y_train_predict) / Y_train)) * 100\n\n        \n    MSE_Train.append(MSE)\n    RMSE_Train.append(RMSE)\n    MAE_Train.append(MAE)\n    MAPE_Train.append(MAPE)\n               \n        \n    MSE = mean_squared_error(Y_test,Y_test_predict)\n    RMSE = np.sqrt(mean_squared_error(Y_test,Y_test_predict))\n    MAE = mean_absolute_error(Y_test,Y_test_predict)\n    MAPE = np.mean(np.abs((Y_test - Y_test_predict) / Y_test)) * 100\n        \n    MSE_Test.append(MSE)\n    RMSE_Test.append(RMSE)\n    MAE_Test.append(MAE)\n    MAPE_Test.append(MAPE)\n    \n        \n    ","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ModelPerformance(algo,performance):\n    print(\"Performance of the model:\", algo)\n    global Hyper, MSE_Train, RMSE_Train,MAE_Train,MSE_Test, RMSE_Test,MAE_Test,MAPE_Train,MAPE_Test\n    \n    display(performance)  \n    if algo == 'XGBoost':\n        plt.figure(figsize=(10,5))\n        sns.lineplot(x=performance[\"No of Trees\"],y=performance[\"MSE-Train\"])\n               \n        sns.lineplot(x=performance[\"No of Trees\"],y=performance[\"MSE-Test\"])\n        plt.xlabel(\"No of Trees\")\n        plt.ylabel(\"MSE-Error\")\n                \n        plt.show()\n        \n    Hyper = []\n    MSE_Train = []\n    RMSE_Train = []\n    MAE_Train = []\n    MSE_Test = []\n    RMSE_Test = []\n    MAE_Test = []\n    MAPE_Train = []\n    MAPE_Test = []\n    MAPE_Train = []\n    MAPE_Test = []\n    ","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ModelFlow()","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"'Shape of the dataframe:'"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(100000, 305)"},"metadata":{}},{"output_type":"stream","text":"**********************************************\nLinear Model Type Build Process starts.....\nFinding Duplicated Data\nTotal number of duplicate records: 0\nDataCleaning Process Starts For Linear.....\nDataAnalysis For Imputation Starts For Linear...\nDrop the features whose greater than equal to 50% of Missing Values:\nDataAnalysis For Imputation Ends For Linear...\nImputation starts for Linear.....\nShape of the Dataframe after Imputation for Linear:\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"(100000, 286)"},"metadata":{}},{"output_type":"stream","text":"Imputation ends for Linear.....\nDataCleaning Process Ends For Linear.....\nIdentifying the relationship of independent and dependent variables for Linear\nImportant Features from Correlation for Linear\nModel Selection Starts for Linear.....\nModel Selection Starts.....\nModel Selection Ends.....\nModel Selection Ends for Linear.....\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n","name":"stderr"},{"output_type":"stream","text":"LinearRegression:\n********Linear Regression Measures****************\nPerformance of the model: linear\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"     MSE-Train     MSE-Test  RMSE-Train  RMSE-Test  MAE-Train   MAE-Test  \\\n0  5277.230236  5267.291288   72.644547  72.576107  56.196942  56.101138   \n\n   MAPE-Train  MAPE-Test  \n0    9.601795    9.52699  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSE-Train</th>\n      <th>MSE-Test</th>\n      <th>RMSE-Train</th>\n      <th>RMSE-Test</th>\n      <th>MAE-Train</th>\n      <th>MAE-Test</th>\n      <th>MAPE-Train</th>\n      <th>MAPE-Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>5277.230236</td>\n      <td>5267.291288</td>\n      <td>72.644547</td>\n      <td>72.576107</td>\n      <td>56.196942</td>\n      <td>56.101138</td>\n      <td>9.601795</td>\n      <td>9.52699</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"RidgeRegression:\n********Ridge Regression Measures****************\nPerformance of the model: Ridge\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"   Penalty    MSE-Train     MSE-Test  RMSE-Train  RMSE-Test  MAE-Train  \\\n0        1  6189.466402  6179.040413   78.673162  78.606873  62.522966   \n1        2  6580.504730  6567.703370   81.120310  81.041368  65.025090   \n2        3  6853.895002  6837.910001   82.788254  82.691656  66.767534   \n3        4  7078.483407  7059.620026   84.133723  84.021545  68.174376   \n4        5  7276.832056  7255.523932   85.304350  85.179363  69.403943   \n5        6  7458.563253  7435.208316   86.362974  86.227654  70.547385   \n6        7  7628.401307  7603.336136   87.340720  87.197111  71.590640   \n7        8  7788.899805  7762.403115   88.254744  88.104501  72.554543   \n8        9  7941.554324  7913.856049   89.115399  88.959856  73.453213   \n\n    MAE-Test  MAPE-Train  MAPE-Test  \n0  62.544111   10.606769  10.555545  \n1  64.993915   11.006428  10.943905  \n2  66.700928   11.290438  11.219762  \n3  68.092873   11.522517  11.447060  \n4  69.318031   11.726773  11.648448  \n5  70.457033   11.917569  11.836706  \n6  71.496716   12.091853  12.008810  \n7  72.455154   12.252962  12.167611  \n8  73.348881   12.403097  12.315693  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Penalty</th>\n      <th>MSE-Train</th>\n      <th>MSE-Test</th>\n      <th>RMSE-Train</th>\n      <th>RMSE-Test</th>\n      <th>MAE-Train</th>\n      <th>MAE-Test</th>\n      <th>MAPE-Train</th>\n      <th>MAPE-Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>6189.466402</td>\n      <td>6179.040413</td>\n      <td>78.673162</td>\n      <td>78.606873</td>\n      <td>62.522966</td>\n      <td>62.544111</td>\n      <td>10.606769</td>\n      <td>10.555545</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>6580.504730</td>\n      <td>6567.703370</td>\n      <td>81.120310</td>\n      <td>81.041368</td>\n      <td>65.025090</td>\n      <td>64.993915</td>\n      <td>11.006428</td>\n      <td>10.943905</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>6853.895002</td>\n      <td>6837.910001</td>\n      <td>82.788254</td>\n      <td>82.691656</td>\n      <td>66.767534</td>\n      <td>66.700928</td>\n      <td>11.290438</td>\n      <td>11.219762</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>7078.483407</td>\n      <td>7059.620026</td>\n      <td>84.133723</td>\n      <td>84.021545</td>\n      <td>68.174376</td>\n      <td>68.092873</td>\n      <td>11.522517</td>\n      <td>11.447060</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>7276.832056</td>\n      <td>7255.523932</td>\n      <td>85.304350</td>\n      <td>85.179363</td>\n      <td>69.403943</td>\n      <td>69.318031</td>\n      <td>11.726773</td>\n      <td>11.648448</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>6</td>\n      <td>7458.563253</td>\n      <td>7435.208316</td>\n      <td>86.362974</td>\n      <td>86.227654</td>\n      <td>70.547385</td>\n      <td>70.457033</td>\n      <td>11.917569</td>\n      <td>11.836706</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>7</td>\n      <td>7628.401307</td>\n      <td>7603.336136</td>\n      <td>87.340720</td>\n      <td>87.197111</td>\n      <td>71.590640</td>\n      <td>71.496716</td>\n      <td>12.091853</td>\n      <td>12.008810</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>8</td>\n      <td>7788.899805</td>\n      <td>7762.403115</td>\n      <td>88.254744</td>\n      <td>88.104501</td>\n      <td>72.554543</td>\n      <td>72.455154</td>\n      <td>12.252962</td>\n      <td>12.167611</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>9</td>\n      <td>7941.554324</td>\n      <td>7913.856049</td>\n      <td>89.115399</td>\n      <td>88.959856</td>\n      <td>73.453213</td>\n      <td>73.348881</td>\n      <td>12.403097</td>\n      <td>12.315693</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"Linear Model Type Build Process ends.....\n**********************************************\n**********************************************\nTree Model Type Build Process starts.....\nFinding Duplicated Data\nTotal number of duplicate records: 0\nDataCleaning Process Starts For Tree.....\nImputation starts for Tree.....\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"(100000, 286)"},"metadata":{}},{"output_type":"stream","text":"Imputation ends for Tree.....\nDataCleaning Process Ends For Tree.....\nModel Selection Starts for Tree.....\nModel Selection Starts.....\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n","name":"stderr"},{"output_type":"stream","text":"Model Selection Ends.....\nModel Selection Ends for Tree.....\nDecision Tree:\n********Decision Tree Regression Measures****************\nPerformance of the model: ds\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"    TreeDepth    MSE-Train     MSE-Test  RMSE-Train  RMSE-Test  MAE-Train  \\\n0           1  6885.638133  6928.277752   82.979745  83.236277  65.804958   \n1           2  4894.931942  4982.657835   69.963790  70.587944  53.216145   \n2           3  3652.428956  3684.103598   60.435329  60.696817  47.396946   \n3           4  2827.719210  2873.588265   53.176303  53.605860  40.567098   \n4           5  2376.774888  2417.038341   48.752178  49.163384  36.998564   \n5           6  2015.886463  2076.182004   44.898624  45.565140  34.001375   \n6           7  1739.899072  1860.728455   41.712097  43.136162  31.406587   \n7           8  1495.369122  1695.828186   38.670003  41.180435  28.843654   \n8           9  1282.267098  1603.521613   35.808757  40.043996  26.509494   \n9          10  1091.995232  1562.664196   33.045351  39.530548  24.348313   \n10         11   910.201047  1539.724304   30.169538  39.239321  22.104931   \n11         12   737.940207  1546.004192   27.165055  39.319260  19.559456   \n12         13   583.553032  1583.703271   24.156842  39.795770  16.956889   \n13         14   451.503693  1645.703417   21.248616  40.567270  14.390872   \n14         15   340.227863  1698.776142   18.445267  41.216212  11.957256   \n15         16   250.903825  1733.494880   15.839944  41.635260   9.704103   \n16         17   181.615014  1771.298450   13.476461  42.086797   7.741714   \n17         18   129.075251  1812.972715   11.361129  42.579017   6.037887   \n18         19    89.664215  1842.961302    9.469119  42.929725   4.659641   \n\n     MAE-Test  MAPE-Train  MAPE-Test  \n0   65.914559   11.077078  11.037363  \n1   53.595003    9.113816   9.126866  \n2   47.607391    8.056180   8.042954  \n3   40.814733    6.881088   6.883987  \n4   37.393370    6.297463   6.328598  \n5   34.478654    5.781749   5.833226  \n6   32.300721    5.347849   5.472723  \n7   30.547761    4.907443   5.180907  \n8   29.333467    4.503464   4.974038  \n9   28.757036    4.128163   4.888047  \n10  28.305062    3.740122   4.818109  \n11  28.096333    3.301397   4.778759  \n12  28.182879    2.854992   4.799630  \n13  28.430999    2.414460   4.842808  \n14  28.673915    1.996589   4.887066  \n15  28.973887    1.613709   4.941113  \n16  29.254229    1.282058   4.987574  \n17  29.586744    0.995137   5.040292  \n18  29.731340    0.764218   5.068226  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TreeDepth</th>\n      <th>MSE-Train</th>\n      <th>MSE-Test</th>\n      <th>RMSE-Train</th>\n      <th>RMSE-Test</th>\n      <th>MAE-Train</th>\n      <th>MAE-Test</th>\n      <th>MAPE-Train</th>\n      <th>MAPE-Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>6885.638133</td>\n      <td>6928.277752</td>\n      <td>82.979745</td>\n      <td>83.236277</td>\n      <td>65.804958</td>\n      <td>65.914559</td>\n      <td>11.077078</td>\n      <td>11.037363</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>4894.931942</td>\n      <td>4982.657835</td>\n      <td>69.963790</td>\n      <td>70.587944</td>\n      <td>53.216145</td>\n      <td>53.595003</td>\n      <td>9.113816</td>\n      <td>9.126866</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>3652.428956</td>\n      <td>3684.103598</td>\n      <td>60.435329</td>\n      <td>60.696817</td>\n      <td>47.396946</td>\n      <td>47.607391</td>\n      <td>8.056180</td>\n      <td>8.042954</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>2827.719210</td>\n      <td>2873.588265</td>\n      <td>53.176303</td>\n      <td>53.605860</td>\n      <td>40.567098</td>\n      <td>40.814733</td>\n      <td>6.881088</td>\n      <td>6.883987</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>2376.774888</td>\n      <td>2417.038341</td>\n      <td>48.752178</td>\n      <td>49.163384</td>\n      <td>36.998564</td>\n      <td>37.393370</td>\n      <td>6.297463</td>\n      <td>6.328598</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>6</td>\n      <td>2015.886463</td>\n      <td>2076.182004</td>\n      <td>44.898624</td>\n      <td>45.565140</td>\n      <td>34.001375</td>\n      <td>34.478654</td>\n      <td>5.781749</td>\n      <td>5.833226</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>7</td>\n      <td>1739.899072</td>\n      <td>1860.728455</td>\n      <td>41.712097</td>\n      <td>43.136162</td>\n      <td>31.406587</td>\n      <td>32.300721</td>\n      <td>5.347849</td>\n      <td>5.472723</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>8</td>\n      <td>1495.369122</td>\n      <td>1695.828186</td>\n      <td>38.670003</td>\n      <td>41.180435</td>\n      <td>28.843654</td>\n      <td>30.547761</td>\n      <td>4.907443</td>\n      <td>5.180907</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>9</td>\n      <td>1282.267098</td>\n      <td>1603.521613</td>\n      <td>35.808757</td>\n      <td>40.043996</td>\n      <td>26.509494</td>\n      <td>29.333467</td>\n      <td>4.503464</td>\n      <td>4.974038</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>10</td>\n      <td>1091.995232</td>\n      <td>1562.664196</td>\n      <td>33.045351</td>\n      <td>39.530548</td>\n      <td>24.348313</td>\n      <td>28.757036</td>\n      <td>4.128163</td>\n      <td>4.888047</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>11</td>\n      <td>910.201047</td>\n      <td>1539.724304</td>\n      <td>30.169538</td>\n      <td>39.239321</td>\n      <td>22.104931</td>\n      <td>28.305062</td>\n      <td>3.740122</td>\n      <td>4.818109</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>12</td>\n      <td>737.940207</td>\n      <td>1546.004192</td>\n      <td>27.165055</td>\n      <td>39.319260</td>\n      <td>19.559456</td>\n      <td>28.096333</td>\n      <td>3.301397</td>\n      <td>4.778759</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>13</td>\n      <td>583.553032</td>\n      <td>1583.703271</td>\n      <td>24.156842</td>\n      <td>39.795770</td>\n      <td>16.956889</td>\n      <td>28.182879</td>\n      <td>2.854992</td>\n      <td>4.799630</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>14</td>\n      <td>451.503693</td>\n      <td>1645.703417</td>\n      <td>21.248616</td>\n      <td>40.567270</td>\n      <td>14.390872</td>\n      <td>28.430999</td>\n      <td>2.414460</td>\n      <td>4.842808</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>15</td>\n      <td>340.227863</td>\n      <td>1698.776142</td>\n      <td>18.445267</td>\n      <td>41.216212</td>\n      <td>11.957256</td>\n      <td>28.673915</td>\n      <td>1.996589</td>\n      <td>4.887066</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>16</td>\n      <td>250.903825</td>\n      <td>1733.494880</td>\n      <td>15.839944</td>\n      <td>41.635260</td>\n      <td>9.704103</td>\n      <td>28.973887</td>\n      <td>1.613709</td>\n      <td>4.941113</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>17</td>\n      <td>181.615014</td>\n      <td>1771.298450</td>\n      <td>13.476461</td>\n      <td>42.086797</td>\n      <td>7.741714</td>\n      <td>29.254229</td>\n      <td>1.282058</td>\n      <td>4.987574</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>18</td>\n      <td>129.075251</td>\n      <td>1812.972715</td>\n      <td>11.361129</td>\n      <td>42.579017</td>\n      <td>6.037887</td>\n      <td>29.586744</td>\n      <td>0.995137</td>\n      <td>5.040292</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>19</td>\n      <td>89.664215</td>\n      <td>1842.961302</td>\n      <td>9.469119</td>\n      <td>42.929725</td>\n      <td>4.659641</td>\n      <td>29.731340</td>\n      <td>0.764218</td>\n      <td>5.068226</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"**************Random Forest Regressor*****************\nPerformance of the model: RandomForest\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"    No of Trees  Tree Depth    MSE-Train     MSE-Test  RMSE-Train  RMSE-Test  \\\n0            10           1  6853.962964  6896.677235   82.788664  83.046236   \n1            10           3  3463.915864  3495.115901   58.855041  59.119505   \n2            10           5  2218.624642  2263.016130   47.102279  47.571169   \n3            10           7  1506.747183  1613.878284   38.816841  40.173104   \n4            10           9  1044.873407  1276.410926   32.324502  35.726894   \n5            12           1  6853.029741  6895.939151   82.783028  83.041792   \n6            12           3  3426.911454  3458.553789   58.539828  58.809470   \n7            12           5  2203.988449  2247.895146   46.946655  47.411973   \n8            12           7  1499.275444  1605.908940   38.720478  40.073794   \n9            12           9  1036.569817  1267.920737   32.195804  35.607875   \n10           14           1  6851.015657  6894.579480   82.770862  83.033605   \n11           14           3  3431.487422  3463.012386   58.578899  58.847365   \n12           14           5  2201.715195  2244.399407   46.922438  47.375093   \n13           14           7  1500.986993  1607.430047   38.742573  40.092768   \n14           14           9  1034.405086  1264.566766   32.162169  35.560748   \n15           16           1  6850.637498  6894.145164   82.768578  83.030989   \n16           16           3  3445.961258  3478.511357   58.702310  58.978906   \n17           16           5  2194.902204  2235.349345   46.849783  47.279481   \n18           16           7  1494.575855  1596.919372   38.659745  39.961474   \n19           16           9  1029.654733  1254.653945   32.088234  35.421095   \n20           18           1  6852.244463  6895.432228   82.778285  83.038739   \n21           18           3  3459.604383  3491.723613   58.818402  59.090808   \n22           18           5  2191.218537  2234.017170   46.810453  47.265391   \n23           18           7  1492.099198  1594.451032   38.627700  39.930578   \n24           18           9  1026.597563  1253.014029   32.040561  35.397938   \n25           20           1  6852.847249  6895.797199   82.781926  83.040937   \n26           20           3  3438.051682  3471.141074   58.634902  58.916391   \n27           20           5  2185.967551  2228.411994   46.754332  47.206059   \n28           20           7  1490.938361  1592.596244   38.612671  39.907346   \n29           20           9  1023.637342  1249.633881   31.994333  35.350161   \n\n    MAE-Train   MAE-Test  MAPE-Train  MAPE-Test  \n0   65.650752  65.755600   11.051899  11.010442  \n1   46.015523  46.241915    7.833629   7.824586  \n2   35.747195  36.144092    6.086631   6.116462  \n3   29.046267  29.923863    4.940437   5.065699  \n4   24.031099  26.268210    4.082879   4.455977  \n5   65.644091  65.751294   11.052869  11.011809  \n6   45.621948  45.856174    7.764780   7.756936  \n7   35.631992  36.014603    6.069791   6.098515  \n8   28.960965  29.836868    4.924408   5.050130  \n9   23.925223  26.157599    4.063628   4.435882  \n10  65.634096  65.736284   11.049936  11.008092  \n11  45.711448  45.935283    7.781307   7.771979  \n12  35.622570  35.989618    6.069839   6.095857  \n13  28.993444  29.874993    4.930403   5.057786  \n14  23.882571  26.117889    4.056349   4.429166  \n15  65.635880  65.738868   11.050610  11.008837  \n16  45.851089  46.085141    7.804586   7.796663  \n17  35.566239  35.914173    6.061787   6.084091  \n18  28.928044  29.786564    4.920770   5.043350  \n19  23.840455  26.033914    4.050312   4.415761  \n20  65.640765  65.747575   11.051822  11.010672  \n21  45.973468  46.209148    7.824576   7.816819  \n22  35.540532  35.906551    6.057050   6.082911  \n23  28.901986  29.769765    4.916707   5.041266  \n24  23.805158  26.019574    4.044642   4.414132  \n25  65.646539  65.753869   11.053549  11.012498  \n26  45.748900  45.989554    7.785747   7.778806  \n27  35.486580  35.847080    6.049479   6.074567  \n28  28.895361  29.769029    4.915773   5.041367  \n29  23.789734  26.011005    4.042358   4.412751  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No of Trees</th>\n      <th>Tree Depth</th>\n      <th>MSE-Train</th>\n      <th>MSE-Test</th>\n      <th>RMSE-Train</th>\n      <th>RMSE-Test</th>\n      <th>MAE-Train</th>\n      <th>MAE-Test</th>\n      <th>MAPE-Train</th>\n      <th>MAPE-Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>6853.962964</td>\n      <td>6896.677235</td>\n      <td>82.788664</td>\n      <td>83.046236</td>\n      <td>65.650752</td>\n      <td>65.755600</td>\n      <td>11.051899</td>\n      <td>11.010442</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>3463.915864</td>\n      <td>3495.115901</td>\n      <td>58.855041</td>\n      <td>59.119505</td>\n      <td>46.015523</td>\n      <td>46.241915</td>\n      <td>7.833629</td>\n      <td>7.824586</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2218.624642</td>\n      <td>2263.016130</td>\n      <td>47.102279</td>\n      <td>47.571169</td>\n      <td>35.747195</td>\n      <td>36.144092</td>\n      <td>6.086631</td>\n      <td>6.116462</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>1506.747183</td>\n      <td>1613.878284</td>\n      <td>38.816841</td>\n      <td>40.173104</td>\n      <td>29.046267</td>\n      <td>29.923863</td>\n      <td>4.940437</td>\n      <td>5.065699</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10</td>\n      <td>9</td>\n      <td>1044.873407</td>\n      <td>1276.410926</td>\n      <td>32.324502</td>\n      <td>35.726894</td>\n      <td>24.031099</td>\n      <td>26.268210</td>\n      <td>4.082879</td>\n      <td>4.455977</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>12</td>\n      <td>1</td>\n      <td>6853.029741</td>\n      <td>6895.939151</td>\n      <td>82.783028</td>\n      <td>83.041792</td>\n      <td>65.644091</td>\n      <td>65.751294</td>\n      <td>11.052869</td>\n      <td>11.011809</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>12</td>\n      <td>3</td>\n      <td>3426.911454</td>\n      <td>3458.553789</td>\n      <td>58.539828</td>\n      <td>58.809470</td>\n      <td>45.621948</td>\n      <td>45.856174</td>\n      <td>7.764780</td>\n      <td>7.756936</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>12</td>\n      <td>5</td>\n      <td>2203.988449</td>\n      <td>2247.895146</td>\n      <td>46.946655</td>\n      <td>47.411973</td>\n      <td>35.631992</td>\n      <td>36.014603</td>\n      <td>6.069791</td>\n      <td>6.098515</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1499.275444</td>\n      <td>1605.908940</td>\n      <td>38.720478</td>\n      <td>40.073794</td>\n      <td>28.960965</td>\n      <td>29.836868</td>\n      <td>4.924408</td>\n      <td>5.050130</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>12</td>\n      <td>9</td>\n      <td>1036.569817</td>\n      <td>1267.920737</td>\n      <td>32.195804</td>\n      <td>35.607875</td>\n      <td>23.925223</td>\n      <td>26.157599</td>\n      <td>4.063628</td>\n      <td>4.435882</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>14</td>\n      <td>1</td>\n      <td>6851.015657</td>\n      <td>6894.579480</td>\n      <td>82.770862</td>\n      <td>83.033605</td>\n      <td>65.634096</td>\n      <td>65.736284</td>\n      <td>11.049936</td>\n      <td>11.008092</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>14</td>\n      <td>3</td>\n      <td>3431.487422</td>\n      <td>3463.012386</td>\n      <td>58.578899</td>\n      <td>58.847365</td>\n      <td>45.711448</td>\n      <td>45.935283</td>\n      <td>7.781307</td>\n      <td>7.771979</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>14</td>\n      <td>5</td>\n      <td>2201.715195</td>\n      <td>2244.399407</td>\n      <td>46.922438</td>\n      <td>47.375093</td>\n      <td>35.622570</td>\n      <td>35.989618</td>\n      <td>6.069839</td>\n      <td>6.095857</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>14</td>\n      <td>7</td>\n      <td>1500.986993</td>\n      <td>1607.430047</td>\n      <td>38.742573</td>\n      <td>40.092768</td>\n      <td>28.993444</td>\n      <td>29.874993</td>\n      <td>4.930403</td>\n      <td>5.057786</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>14</td>\n      <td>9</td>\n      <td>1034.405086</td>\n      <td>1264.566766</td>\n      <td>32.162169</td>\n      <td>35.560748</td>\n      <td>23.882571</td>\n      <td>26.117889</td>\n      <td>4.056349</td>\n      <td>4.429166</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>16</td>\n      <td>1</td>\n      <td>6850.637498</td>\n      <td>6894.145164</td>\n      <td>82.768578</td>\n      <td>83.030989</td>\n      <td>65.635880</td>\n      <td>65.738868</td>\n      <td>11.050610</td>\n      <td>11.008837</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>16</td>\n      <td>3</td>\n      <td>3445.961258</td>\n      <td>3478.511357</td>\n      <td>58.702310</td>\n      <td>58.978906</td>\n      <td>45.851089</td>\n      <td>46.085141</td>\n      <td>7.804586</td>\n      <td>7.796663</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>16</td>\n      <td>5</td>\n      <td>2194.902204</td>\n      <td>2235.349345</td>\n      <td>46.849783</td>\n      <td>47.279481</td>\n      <td>35.566239</td>\n      <td>35.914173</td>\n      <td>6.061787</td>\n      <td>6.084091</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>16</td>\n      <td>7</td>\n      <td>1494.575855</td>\n      <td>1596.919372</td>\n      <td>38.659745</td>\n      <td>39.961474</td>\n      <td>28.928044</td>\n      <td>29.786564</td>\n      <td>4.920770</td>\n      <td>5.043350</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>16</td>\n      <td>9</td>\n      <td>1029.654733</td>\n      <td>1254.653945</td>\n      <td>32.088234</td>\n      <td>35.421095</td>\n      <td>23.840455</td>\n      <td>26.033914</td>\n      <td>4.050312</td>\n      <td>4.415761</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>18</td>\n      <td>1</td>\n      <td>6852.244463</td>\n      <td>6895.432228</td>\n      <td>82.778285</td>\n      <td>83.038739</td>\n      <td>65.640765</td>\n      <td>65.747575</td>\n      <td>11.051822</td>\n      <td>11.010672</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>18</td>\n      <td>3</td>\n      <td>3459.604383</td>\n      <td>3491.723613</td>\n      <td>58.818402</td>\n      <td>59.090808</td>\n      <td>45.973468</td>\n      <td>46.209148</td>\n      <td>7.824576</td>\n      <td>7.816819</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>18</td>\n      <td>5</td>\n      <td>2191.218537</td>\n      <td>2234.017170</td>\n      <td>46.810453</td>\n      <td>47.265391</td>\n      <td>35.540532</td>\n      <td>35.906551</td>\n      <td>6.057050</td>\n      <td>6.082911</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>18</td>\n      <td>7</td>\n      <td>1492.099198</td>\n      <td>1594.451032</td>\n      <td>38.627700</td>\n      <td>39.930578</td>\n      <td>28.901986</td>\n      <td>29.769765</td>\n      <td>4.916707</td>\n      <td>5.041266</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>18</td>\n      <td>9</td>\n      <td>1026.597563</td>\n      <td>1253.014029</td>\n      <td>32.040561</td>\n      <td>35.397938</td>\n      <td>23.805158</td>\n      <td>26.019574</td>\n      <td>4.044642</td>\n      <td>4.414132</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>20</td>\n      <td>1</td>\n      <td>6852.847249</td>\n      <td>6895.797199</td>\n      <td>82.781926</td>\n      <td>83.040937</td>\n      <td>65.646539</td>\n      <td>65.753869</td>\n      <td>11.053549</td>\n      <td>11.012498</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>20</td>\n      <td>3</td>\n      <td>3438.051682</td>\n      <td>3471.141074</td>\n      <td>58.634902</td>\n      <td>58.916391</td>\n      <td>45.748900</td>\n      <td>45.989554</td>\n      <td>7.785747</td>\n      <td>7.778806</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>20</td>\n      <td>5</td>\n      <td>2185.967551</td>\n      <td>2228.411994</td>\n      <td>46.754332</td>\n      <td>47.206059</td>\n      <td>35.486580</td>\n      <td>35.847080</td>\n      <td>6.049479</td>\n      <td>6.074567</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>20</td>\n      <td>7</td>\n      <td>1490.938361</td>\n      <td>1592.596244</td>\n      <td>38.612671</td>\n      <td>39.907346</td>\n      <td>28.895361</td>\n      <td>29.769029</td>\n      <td>4.915773</td>\n      <td>5.041367</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>20</td>\n      <td>9</td>\n      <td>1023.637342</td>\n      <td>1249.633881</td>\n      <td>31.994333</td>\n      <td>35.350161</td>\n      <td>23.789734</td>\n      <td>26.011005</td>\n      <td>4.042358</td>\n      <td>4.412751</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"**************XGBOOST**********************\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n  if getattr(data, 'base', None) is not None and \\\n","name":"stderr"},{"output_type":"stream","text":"Performance of the model: XGBoost\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"   No of Trees  Tree Depth    MSE-Train     MSE-Test  RMSE-Train  RMSE-Test  \\\n0         1000           9  1014.167963  1061.014269   31.846004  32.573214   \n\n   MAE-Train   MAE-Test  MAPE-Train  MAPE-Test  \n0  23.513601  23.952379    4.009296   4.059625  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No of Trees</th>\n      <th>Tree Depth</th>\n      <th>MSE-Train</th>\n      <th>MSE-Test</th>\n      <th>RMSE-Train</th>\n      <th>RMSE-Test</th>\n      <th>MAE-Train</th>\n      <th>MAE-Test</th>\n      <th>MAPE-Train</th>\n      <th>MAPE-Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1000</td>\n      <td>9</td>\n      <td>1014.167963</td>\n      <td>1061.014269</td>\n      <td>31.846004</td>\n      <td>32.573214</td>\n      <td>23.513601</td>\n      <td>23.952379</td>\n      <td>4.009296</td>\n      <td>4.059625</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":"**********************************************\nTree Model Type Build Process ends.....\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}